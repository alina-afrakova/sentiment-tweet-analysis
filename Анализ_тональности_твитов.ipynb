{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Анализ тональности твитов.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QyYRCfQ0ZqsD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Монтировка диска\n",
        "для доступа к файлам с датасетами (*'train.xml'* и *'test_etalon.xml'*)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PNqiea2_Tasu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IqJhIi8Y9TA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1453405d-d350-4dd0-a9ff-32fb4921ca32"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Чтение данных из файлов\n",
        "- Парсинг xml файлов в `pandas.dataframe` с помощью библиотеки `xml.etree.ElementTree`"
      ],
      "metadata": {
        "id": "QJdOcc8IUWdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqJxd9onBObc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "b5432827-53a0-4e7b-9b3b-6a6259597a9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitid</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>beeline</th>\n",
              "      <th>mts</th>\n",
              "      <th>megafon</th>\n",
              "      <th>tele2</th>\n",
              "      <th>rostelecom</th>\n",
              "      <th>komstar</th>\n",
              "      <th>skylink</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>492367588165680000</td>\n",
              "      <td>1406224555</td>\n",
              "      <td>@mkomov Максим, Вашем письмо мы получили. Наши...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>492369449912380000</td>\n",
              "      <td>1406224999</td>\n",
              "      <td>«Мегафон» стал владельцем 50% акций «Евросети»</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>492369715378290000</td>\n",
              "      <td>1406225062</td>\n",
              "      <td>RT @fuckkiev: “@EvaKobb: МТС Россия прислала ж...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>492369842205650000</td>\n",
              "      <td>1406225092</td>\n",
              "      <td>ВИДЕО: http://t.co/PSMLAhR4fI Реклама со смехо...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>492371322060950000</td>\n",
              "      <td>1406225445</td>\n",
              "      <td>@parfenov1960 потому что МТС достало, а пчел н...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>497357408235420000</td>\n",
              "      <td>1407414221</td>\n",
              "      <td>Блогеры и журналисты Ставрополя публично проте...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>497358002065010000</td>\n",
              "      <td>1407414362</td>\n",
              "      <td>В Крыму полностью отключили инфраструктуру «МТ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>497358112610070000</td>\n",
              "      <td>1407414389</td>\n",
              "      <td>Кавказский #МегаФон предлагает новым корпорати...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>497358154074960000</td>\n",
              "      <td>1407414399</td>\n",
              "      <td>28 июня с 14:00 до 22:00 на Адмиралтейской пло...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5000</th>\n",
              "      <td>497358309822040000</td>\n",
              "      <td>1407414436</td>\n",
              "      <td>Абоненты Tele2 выбирают смартфоны</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  twitid        date  ... komstar skylink\n",
              "id                                    ...                \n",
              "1     492367588165680000  1406224555  ...     NaN     NaN\n",
              "2     492369449912380000  1406224999  ...     NaN     NaN\n",
              "3     492369715378290000  1406225062  ...     NaN     NaN\n",
              "4     492369842205650000  1406225092  ...     NaN     NaN\n",
              "5     492371322060950000  1406225445  ...     NaN     NaN\n",
              "...                  ...         ...  ...     ...     ...\n",
              "4996  497357408235420000  1407414221  ...     NaN     NaN\n",
              "4997  497358002065010000  1407414362  ...     NaN     NaN\n",
              "4998  497358112610070000  1407414389  ...     NaN     NaN\n",
              "4999  497358154074960000  1407414399  ...     NaN     NaN\n",
              "5000  497358309822040000  1407414436  ...     NaN     NaN\n",
              "\n",
              "[5000 rows x 10 columns]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "  \n",
        "def xml_to_df(file_name):\n",
        "    tree = ET.parse(file_name)\n",
        "    root = tree.getroot() [1]\n",
        "    all_records = []\n",
        "    for i, child in enumerate(root):\n",
        "        record = {}\n",
        "        for sub_child in child:\n",
        "            key = sub_child.attrib['name']\n",
        "            value = sub_child.text\n",
        "            if value == 'NULL':\n",
        "                value = np.nan\n",
        "            if key == 'id' or key == 'twitid':\n",
        "                value = int(value)\n",
        "            record[key] = value\n",
        "        all_records.append(record)\n",
        "    return pd.DataFrame(all_records).set_index('id')\n",
        "\n",
        "\n",
        "train_file = \"/content/drive/MyDrive/classf/train.xml\"\n",
        "test_file = \"/content/drive/MyDrive/classf/test_etalon.xml\"\n",
        "df_train = xml_to_df(train_file)\n",
        "df_test = xml_to_df(test_file)\n",
        "\n",
        "display(df_train)\n",
        "\n",
        "# with open(train_file, 'r', encoding='utf-8') as train:\n",
        "#     df_train = pd.read_xml(train.read(),  xpath=\"//column\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `установка вспомогательных библиотек`"
      ],
      "metadata": {
        "id": "QyYRCfQ0ZqsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wDclonQpb7",
        "outputId": "3ae6508a-a950-4b13-c360-f896c55b6ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GnHp60TAJcG",
        "outputId": "17edd969-5349-41c8-c4fb-2623501954d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Предобработка датасета\n",
        "- Приведение некоторых типов `obj` к `int` \n",
        "- Добавление столбца `class` (1, -1, 0 - суммарный класс твита какой-либо компании)\n",
        "- Фильтрование полученных таблиц\n",
        "- Добавление столбца `data` (список токенов без стоп-слов - предобработанный текст твитов с помощью библиотек `nltk` и `pymorphy2`)"
      ],
      "metadata": {
        "id": "o843zvwEU1sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "\n",
        "def extract_tokens(text):   \n",
        "    stop_words = set(stopwords.words('russian')) | set('без был вам вас ваш вон вот все всю вся всё весь про раз сам сих так там тем тех том тот тою будто тоже пока пора это теми того тоже тому туда хоть хотя мимо для его ему еще ещё или ими как кем ком кто мне мог мож мои мой моя моё над нам нас наш нее ней нем нет нею неё них оба она они оно под пор при про раз сам сих так там тем тех том тот тою три тут уже чем что эта эти это эту'.split())\n",
        "    rus_chars = set(chr(i) for i in range(ord('а'), ord('а') + 32)) | set('ё')\n",
        "    marks = set(punctuation) | set('«»—…')\n",
        "\n",
        "    words = word_tokenize(text.replace('#', ' '), 'russian')\n",
        "    def del_mark(word):\n",
        "        if word and word[0] in marks: word = word[1:]\n",
        "        if word and word[-1] in marks: word = word[:-1]\n",
        "        return word\n",
        "    words = [del_mark(word) for word in words]\n",
        "    words = [word for word in words if not word.lower() in stop_words\n",
        "            and len(word) > 2 and not set(word.lower()) - rus_chars]\n",
        "    \n",
        "    tokens = [pm2.parse(word)[0].normal_form for word in words \n",
        "              if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def transform_df(df):\n",
        "    pd.set_option('mode.chained_assignment', None)\n",
        "\n",
        "    companies = df.columns[3:]\n",
        "    for column in companies:\n",
        "        df[column] = pd.to_numeric(df[column], errors='coerce') # if error of int(), then NaN\n",
        "    \n",
        "    df['class'] = df[companies].max(axis=1)\n",
        "    df = df[~df['class'].isna()]\n",
        "    df['class'] = df['class'].astype('int64')\n",
        "\n",
        "    df['data'] = df['text'].apply(extract_tokens)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "pm2 = MorphAnalyzer()\n",
        "df_train = transform_df(df_train)\n",
        "df_test = transform_df(df_test)\n",
        "\n",
        "display(df_train)\n",
        "print()\n",
        "print(df_train[\"class\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "3nOu5Q5dGWr_",
        "outputId": "30c34c30-1676-4072-81bc-c3532a61ef87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitid</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>beeline</th>\n",
              "      <th>mts</th>\n",
              "      <th>megafon</th>\n",
              "      <th>tele2</th>\n",
              "      <th>rostelecom</th>\n",
              "      <th>komstar</th>\n",
              "      <th>skylink</th>\n",
              "      <th>class</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>492367588165680000</td>\n",
              "      <td>1406224555</td>\n",
              "      <td>@mkomov Максим, Вашем письмо мы получили. Наши...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[максим, ваш, письмо, получить, наш, сотрудник...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>492369449912380000</td>\n",
              "      <td>1406224999</td>\n",
              "      <td>«Мегафон» стал владельцем 50% акций «Евросети»</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[мегафон, стать, владелец, акция, евросеть]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>492369715378290000</td>\n",
              "      <td>1406225062</td>\n",
              "      <td>RT @fuckkiev: “@EvaKobb: МТС Россия прислала ж...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>[мтс, россия, прислать, житель, херсонщина, со...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>492369842205650000</td>\n",
              "      <td>1406225092</td>\n",
              "      <td>ВИДЕО: http://t.co/PSMLAhR4fI Реклама со смехо...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>[видео, реклама, смех, мтс, супер]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>492371322060950000</td>\n",
              "      <td>1406225445</td>\n",
              "      <td>@parfenov1960 потому что МТС достало, а пчел н...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>[мтс, достать, пчела, ненавидеть, детство, мёд]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>497357408235420000</td>\n",
              "      <td>1407414221</td>\n",
              "      <td>Блогеры и журналисты Ставрополя публично проте...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[блогер, журналист, ставрополь, публично, прот...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>497358002065010000</td>\n",
              "      <td>1407414362</td>\n",
              "      <td>В Крыму полностью отключили инфраструктуру «МТ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[крым, полностью, отключить, инфраструктура, м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>497358112610070000</td>\n",
              "      <td>1407414389</td>\n",
              "      <td>Кавказский #МегаФон предлагает новым корпорати...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>[кавказский, мегафон, предлагать, новый, корпо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>497358154074960000</td>\n",
              "      <td>1407414399</td>\n",
              "      <td>28 июня с 14:00 до 22:00 на Адмиралтейской пло...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[июнь, адмиралтейский, площадь, поддержка, ком...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5000</th>\n",
              "      <td>497358309822040000</td>\n",
              "      <td>1407414436</td>\n",
              "      <td>Абоненты Tele2 выбирают смартфоны</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[абонент, выбирать, смартфон]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4799 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  twitid  ...                                               data\n",
              "id                        ...                                                   \n",
              "1     492367588165680000  ...  [максим, ваш, письмо, получить, наш, сотрудник...\n",
              "2     492369449912380000  ...        [мегафон, стать, владелец, акция, евросеть]\n",
              "3     492369715378290000  ...  [мтс, россия, прислать, житель, херсонщина, со...\n",
              "4     492369842205650000  ...                 [видео, реклама, смех, мтс, супер]\n",
              "5     492371322060950000  ...    [мтс, достать, пчела, ненавидеть, детство, мёд]\n",
              "...                  ...  ...                                                ...\n",
              "4996  497357408235420000  ...  [блогер, журналист, ставрополь, публично, прот...\n",
              "4997  497358002065010000  ...  [крым, полностью, отключить, инфраструктура, м...\n",
              "4998  497358112610070000  ...  [кавказский, мегафон, предлагать, новый, корпо...\n",
              "4999  497358154074960000  ...  [июнь, адмиралтейский, площадь, поддержка, ком...\n",
              "5000  497358309822040000  ...                      [абонент, выбирать, смартфон]\n",
              "\n",
              "[4799 rows x 12 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 0    2258\n",
            "-1    1585\n",
            " 1     956\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Обучение модели-классификатора `KNeighborsClassifier` \n",
        "- с различными параметрами и разными способами векторизации слов\n",
        "- оценивание каждой модели с целью выбора наилучшей"
      ],
      "metadata": {
        "id": "r1MTSkylYu3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_cv_score(X_tr, y_train, X_te, y_test, parameters, score_functions, acc_function, knn_class):\n",
        "    \"\"\"Takes train data, counts score over grid of parameters (all possible parameters combinations) \n",
        "\n",
        "    Parameters:\n",
        "    X_tr (2d np.array): train set\n",
        "    y_train (1d np.array): train labels\n",
        "    X_te (2d np.array): test set\n",
        "    y_test (1d np.array): test labels\n",
        "    parameters (dict): dict with keys from {n_neighbors, metrics, weights, normalizers}, values of type list,\n",
        "                       parameters['normalizers'] contains tuples (normalizer, normalizer_name), see parameters\n",
        "                       example in your jupyter notebook\n",
        "    acc_function (callable): function with input (y_true, y_predict) which outputs score metric\n",
        "    knn_class (obj): class of knn model to fit\n",
        "\n",
        "    Returns:\n",
        "    dict: key - tuple of (normalizer_name, n_neighbors, metric, weight), value - score\n",
        "    \"\"\"\n",
        "    output = {}\n",
        "    for normalizer, normalizer_name in parameters['normalizers']:\n",
        "        if normalizer:\n",
        "            normalizer.fit(X_tr)\n",
        "            #normalizer.fit_transform(df_train.data).toarray()\n",
        "            X_train = normalizer.transform(X_tr).toarray()\n",
        "            X_test = normalizer.transform(X_te).toarray()\n",
        "\n",
        "        for n_neighbors in parameters['n_neighbors']:\n",
        "            for metric in parameters['metrics']:\n",
        "                for weight in parameters['weights']:\n",
        "                    key = (normalizer_name, n_neighbors, metric, weight)\n",
        "                    \n",
        "                    classifier = knn_class(n_neighbors, weights=weight, metric=metric)\n",
        "                    classifier.fit(X_train, y_train)\n",
        "                    y_pred = classifier.predict(X_test)\n",
        "\n",
        "                    output[key] = [score(y_test, y_pred, average='macro', zero_division=1) \n",
        "                                    for score in score_functions]\n",
        "                    output[key].append(acc_function(y_test, y_pred))\n",
        "    return output"
      ],
      "metadata": {
        "id": "YQf9sDgzjWAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "count_vec = CountVectorizer(analyzer=lambda x: x) # max_df=0.8, min_df=10, stop_words='russian'\n",
        "tf_idf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': [i for i in range(1, 8)],\n",
        "    'metrics': ['euclidean', 'cosine'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'normalizers': [(count_vec, 'CountVectorizer'), (tf_idf, 'TfidfVectorizer')]\n",
        "}\n",
        "\n",
        "results = knn_cv_score(df_train['data'], df_train['class'], df_test['data'], df_test['class'], \n",
        "                       parameters, [precision_score, recall_score, f1_score], accuracy_score, \n",
        "                       KNeighborsClassifier)\n",
        "\n",
        "print(\"Различные параметры классификатора KNN и оценочные метрики для каждой модели:\\n\")\n",
        "print(\"(normalizer, n_neighbors, metric, weight): [precision, recall, f1_score, accuracy]\\n\")\n",
        "print(*[f\"{key}:\" + \" [\" + ', '.join([f\"{score:.4f}\"for score in scores]) + \"]\"\n",
        "          for key, scores in results.items()], sep='\\n')\n",
        "\n",
        "best_model = max(results.items(), key=lambda t: t[1][-1])\n",
        "print(\"\\nНаилучшая модель по аккуратности:\\n\", *best_model, sep='\\n')\n",
        "\n",
        "best_model = max(results.items(), key=lambda t: t[1][-2])\n",
        "print(\"\\nНаилучшая модель по F-мере:\\n\", *best_model, sep='\\n')"
      ],
      "metadata": {
        "id": "sR_y4albaG-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d8a86c-974a-48dd-f80f-65e8193f4c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Различные параметры классификатора KNN и оценочные метрики для каждой модели:\n",
            "\n",
            "(normalizer, n_neighbors, metric, weight): [precision, recall, f1_score, accuracy]\n",
            "\n",
            "('CountVectorizer', 1, 'euclidean', 'uniform'): [0.4074, 0.3873, 0.3912, 0.6000]\n",
            "('CountVectorizer', 1, 'euclidean', 'distance'): [0.4074, 0.3873, 0.3912, 0.6000]\n",
            "('CountVectorizer', 1, 'cosine', 'uniform'): [0.4891, 0.4668, 0.4737, 0.6466]\n",
            "('CountVectorizer', 1, 'cosine', 'distance'): [0.4891, 0.4668, 0.4737, 0.6466]\n",
            "('CountVectorizer', 2, 'euclidean', 'uniform'): [0.4614, 0.3840, 0.3714, 0.5997]\n",
            "('CountVectorizer', 2, 'euclidean', 'distance'): [0.4018, 0.3835, 0.3847, 0.5956]\n",
            "('CountVectorizer', 2, 'cosine', 'uniform'): [0.4666, 0.4507, 0.4471, 0.6481]\n",
            "('CountVectorizer', 2, 'cosine', 'distance'): [0.4867, 0.4745, 0.4795, 0.6460]\n",
            "('CountVectorizer', 3, 'euclidean', 'uniform'): [0.4857, 0.3661, 0.3477, 0.6679]\n",
            "('CountVectorizer', 3, 'euclidean', 'distance'): [0.4344, 0.3613, 0.3420, 0.6624]\n",
            "('CountVectorizer', 3, 'cosine', 'uniform'): [0.4706, 0.4385, 0.4480, 0.6505]\n",
            "('CountVectorizer', 3, 'cosine', 'distance'): [0.4794, 0.4381, 0.4493, 0.6536]\n",
            "('CountVectorizer', 4, 'euclidean', 'uniform'): [0.5364, 0.3799, 0.3699, 0.6772]\n",
            "('CountVectorizer', 4, 'euclidean', 'distance'): [0.5072, 0.3835, 0.3749, 0.6736]\n",
            "('CountVectorizer', 4, 'cosine', 'uniform'): [0.4781, 0.4515, 0.4604, 0.6544]\n",
            "('CountVectorizer', 4, 'cosine', 'distance'): [0.4980, 0.4667, 0.4766, 0.6557]\n",
            "('CountVectorizer', 5, 'euclidean', 'uniform'): [0.5484, 0.3838, 0.3718, 0.6814]\n",
            "('CountVectorizer', 5, 'euclidean', 'distance'): [0.5494, 0.3881, 0.3784, 0.6796]\n",
            "('CountVectorizer', 5, 'cosine', 'uniform'): [0.4930, 0.4567, 0.4682, 0.6546]\n",
            "('CountVectorizer', 5, 'cosine', 'distance'): [0.4980, 0.4579, 0.4683, 0.6538]\n",
            "('CountVectorizer', 6, 'euclidean', 'uniform'): [0.5677, 0.3762, 0.3575, 0.6824]\n",
            "('CountVectorizer', 6, 'euclidean', 'distance'): [0.5681, 0.3823, 0.3670, 0.6819]\n",
            "('CountVectorizer', 6, 'cosine', 'uniform'): [0.4937, 0.4540, 0.4661, 0.6603]\n",
            "('CountVectorizer', 6, 'cosine', 'distance'): [0.5053, 0.4586, 0.4702, 0.6588]\n",
            "('CountVectorizer', 7, 'euclidean', 'uniform'): [0.5954, 0.3773, 0.3579, 0.6824]\n",
            "('CountVectorizer', 7, 'euclidean', 'distance'): [0.5782, 0.3789, 0.3611, 0.6804]\n",
            "('CountVectorizer', 7, 'cosine', 'uniform'): [0.4981, 0.4541, 0.4666, 0.6596]\n",
            "('CountVectorizer', 7, 'cosine', 'distance'): [0.5067, 0.4565, 0.4691, 0.6614]\n",
            "('TfidfVectorizer', 1, 'euclidean', 'uniform'): [0.4778, 0.4480, 0.3653, 0.4299]\n",
            "('TfidfVectorizer', 1, 'euclidean', 'distance'): [0.4778, 0.4480, 0.3653, 0.4299]\n",
            "('TfidfVectorizer', 1, 'cosine', 'uniform'): [0.4986, 0.5169, 0.5028, 0.6250]\n",
            "('TfidfVectorizer', 1, 'cosine', 'distance'): [0.4986, 0.5169, 0.5028, 0.6250]\n",
            "('TfidfVectorizer', 2, 'euclidean', 'uniform'): [0.4740, 0.4047, 0.2786, 0.3678]\n",
            "('TfidfVectorizer', 2, 'euclidean', 'distance'): [0.4809, 0.4493, 0.3659, 0.4304]\n",
            "('TfidfVectorizer', 2, 'cosine', 'uniform'): [0.5064, 0.5174, 0.4988, 0.6437]\n",
            "('TfidfVectorizer', 2, 'cosine', 'distance'): [0.4996, 0.5190, 0.5044, 0.6260]\n",
            "('TfidfVectorizer', 3, 'euclidean', 'uniform'): [0.4950, 0.3871, 0.3847, 0.6658]\n",
            "('TfidfVectorizer', 3, 'euclidean', 'distance'): [0.5220, 0.4085, 0.4144, 0.6723]\n",
            "('TfidfVectorizer', 3, 'cosine', 'uniform'): [0.5061, 0.5255, 0.5139, 0.6416]\n",
            "('TfidfVectorizer', 3, 'cosine', 'distance'): [0.5164, 0.5286, 0.5196, 0.6489]\n",
            "('TfidfVectorizer', 4, 'euclidean', 'uniform'): [0.5219, 0.3741, 0.3601, 0.6762]\n",
            "('TfidfVectorizer', 4, 'euclidean', 'distance'): [0.5357, 0.3874, 0.3816, 0.6754]\n",
            "('TfidfVectorizer', 4, 'cosine', 'uniform'): [0.5273, 0.5421, 0.5337, 0.6648]\n",
            "('TfidfVectorizer', 4, 'cosine', 'distance'): [0.5374, 0.5501, 0.5403, 0.6668]\n",
            "('TfidfVectorizer', 5, 'euclidean', 'uniform'): [0.5582, 0.3718, 0.3529, 0.6780]\n",
            "('TfidfVectorizer', 5, 'euclidean', 'distance'): [0.5397, 0.3811, 0.3687, 0.6754]\n",
            "('TfidfVectorizer', 5, 'cosine', 'uniform'): [0.5299, 0.5402, 0.5346, 0.6658]\n",
            "('TfidfVectorizer', 5, 'cosine', 'distance'): [0.5396, 0.5497, 0.5409, 0.6684]\n",
            "('TfidfVectorizer', 6, 'euclidean', 'uniform'): [0.5037, 0.3535, 0.3186, 0.6723]\n",
            "('TfidfVectorizer', 6, 'euclidean', 'distance'): [0.5262, 0.3632, 0.3374, 0.6739]\n",
            "('TfidfVectorizer', 6, 'cosine', 'uniform'): [0.5384, 0.5488, 0.5432, 0.6749]\n",
            "('TfidfVectorizer', 6, 'cosine', 'distance'): [0.5464, 0.5514, 0.5459, 0.6772]\n",
            "('TfidfVectorizer', 7, 'euclidean', 'uniform'): [0.5846, 0.3662, 0.3399, 0.6801]\n",
            "('TfidfVectorizer', 7, 'euclidean', 'distance'): [0.5707, 0.3711, 0.3495, 0.6788]\n",
            "('TfidfVectorizer', 7, 'cosine', 'uniform'): [0.5351, 0.5392, 0.5369, 0.6723]\n",
            "('TfidfVectorizer', 7, 'cosine', 'distance'): [0.5425, 0.5450, 0.5412, 0.6739]\n",
            "\n",
            "Наилучшая модель по аккуратности:\n",
            "\n",
            "('CountVectorizer', 6, 'euclidean', 'uniform')\n",
            "[0.5677490364727712, 0.3762347506628984, 0.35754758166589395, 0.682444733420026]\n",
            "\n",
            "Наилучшая модель по F-мере:\n",
            "\n",
            "('TfidfVectorizer', 6, 'cosine', 'distance')\n",
            "[0.5464415917475179, 0.5513833978812228, 0.5458647879233091, 0.6772431729518855]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Обучение модели-классификатора `RandomForestClassifier` \n",
        "- с различными параметрами и разными способами векторизации слов\n",
        "- оценивание каждой модели с целью выбора наилучшей"
      ],
      "metadata": {
        "id": "SDQaDW-KbySV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forest_cv_score(X_tr, y_train, X_te, y_test, parameters, score_functions, acc_function, forest_class):\n",
        "    output = {}\n",
        "    for normalizer, normalizer_name in parameters['normalizers']:\n",
        "        if normalizer:\n",
        "            normalizer.fit(X_tr)\n",
        "            #normalizer.fit_transform(df_train.data).toarray()\n",
        "            X_train = normalizer.transform(X_tr).toarray()\n",
        "            X_test = normalizer.transform(X_te).toarray()\n",
        "\n",
        "        for n_estimators in parameters['n_estimators']:\n",
        "            for max_features in parameters['max_features']:\n",
        "                for bootstrap in parameters['bootstrap']:\n",
        "                    key = (normalizer_name, n_estimators, max_features, bootstrap)\n",
        "\n",
        "                    classifier = forest_class(n_estimators, max_features=max_features, bootstrap=bootstrap)\n",
        "                    classifier.fit(X_train, y_train)\n",
        "                    y_pred = classifier.predict(X_test)\n",
        "\n",
        "                    output[key] = [score(y_test, y_pred, average='macro', zero_division=1) \n",
        "                                    for score in score_functions]\n",
        "                    output[key].append(acc_function(y_test, y_pred))\n",
        "    return output"
      ],
      "metadata": {
        "id": "4lFzKUEQQ1cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "count_vec = CountVectorizer(analyzer=lambda x: x)\n",
        "tf_idf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "\n",
        "parameters = {\n",
        "    'n_estimators': [i for i in range(100, 301, 100)],\n",
        "    'max_features': ['log2', 'sqrt'],\n",
        "    'bootstrap': [True, False],\n",
        "    'normalizers': [(count_vec, 'CountVectorizer'), (tf_idf, 'TfidfVectorizer')]\n",
        "}\n",
        "\n",
        "results = forest_cv_score(df_train['data'], df_train['class'], df_test['data'], df_test['class'], \n",
        "                          parameters, [precision_score, recall_score, f1_score], accuracy_score, \n",
        "                          RandomForestClassifier)\n",
        "\n",
        "print(\"Различные параметры классификатора RandomForest и оценочные метрики для каждой модели:\\n\")\n",
        "print(\"(normalizer, n_estimators, max_features, bootstrap): [precision, recall, f1_score, accuracy]\\n\")\n",
        "print(*[f\"{key}:\" + \" [\" + ', '.join([f\"{score:.4f}\"for score in scores]) + \"]\"\n",
        "          for key, scores in results.items()], sep='\\n')\n",
        "\n",
        "best_model = max(results.items(), key=lambda t: t[1][-1])\n",
        "print(\"\\nНаилучшая модель по аккуратности:\\n\", *best_model, sep='\\n')\n",
        "\n",
        "best_model = max(results.items(), key=lambda t: t[1][-2])\n",
        "print(\"\\nНаилучшая модель по F-мере:\\n\", *best_model, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OorUixJc-ZSI",
        "outputId": "9f57a201-43f2-4f8f-f4c1-f29ba7dbbc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Различные параметры классификатора RandomForest и оценочные метрики для каждой модели:\n",
            "\n",
            "(normalizer, n_estimators, max_features, bootstrap): [precision, recall, f1_score, accuracy]\n",
            "\n",
            "('CountVectorizer', 100, 'log2', True): [0.5800, 0.5362, 0.5531, 0.7111]\n",
            "('CountVectorizer', 100, 'log2', False): [0.5646, 0.5389, 0.5497, 0.7022]\n",
            "('CountVectorizer', 100, 'sqrt', True): [0.5508, 0.5222, 0.5340, 0.6884]\n",
            "('CountVectorizer', 100, 'sqrt', False): [0.5255, 0.5167, 0.5208, 0.6681]\n",
            "('CountVectorizer', 200, 'log2', True): [0.5734, 0.5171, 0.5365, 0.7082]\n",
            "('CountVectorizer', 200, 'log2', False): [0.5687, 0.5385, 0.5510, 0.7020]\n",
            "('CountVectorizer', 200, 'sqrt', True): [0.5561, 0.5286, 0.5401, 0.6926]\n",
            "('CountVectorizer', 200, 'sqrt', False): [0.5246, 0.5169, 0.5204, 0.6668]\n",
            "('CountVectorizer', 300, 'log2', True): [0.5809, 0.5231, 0.5434, 0.7098]\n",
            "('CountVectorizer', 300, 'log2', False): [0.5696, 0.5346, 0.5486, 0.7048]\n",
            "('CountVectorizer', 300, 'sqrt', True): [0.5544, 0.5262, 0.5378, 0.6915]\n",
            "('CountVectorizer', 300, 'sqrt', False): [0.5263, 0.5200, 0.5227, 0.6668]\n",
            "('TfidfVectorizer', 100, 'log2', True): [0.5819, 0.5621, 0.5693, 0.7152]\n",
            "('TfidfVectorizer', 100, 'log2', False): [0.5729, 0.5775, 0.5733, 0.7022]\n",
            "('TfidfVectorizer', 100, 'sqrt', True): [0.5500, 0.5411, 0.5438, 0.6845]\n",
            "('TfidfVectorizer', 100, 'sqrt', False): [0.5408, 0.5512, 0.5453, 0.6775]\n",
            "('TfidfVectorizer', 200, 'log2', True): [0.5857, 0.5700, 0.5761, 0.7170]\n",
            "('TfidfVectorizer', 200, 'log2', False): [0.5752, 0.5819, 0.5767, 0.7048]\n",
            "('TfidfVectorizer', 200, 'sqrt', True): [0.5586, 0.5449, 0.5493, 0.6902]\n",
            "('TfidfVectorizer', 200, 'sqrt', False): [0.5439, 0.5519, 0.5469, 0.6785]\n",
            "('TfidfVectorizer', 300, 'log2', True): [0.5781, 0.5580, 0.5653, 0.7129]\n",
            "('TfidfVectorizer', 300, 'log2', False): [0.5783, 0.5837, 0.5791, 0.7090]\n",
            "('TfidfVectorizer', 300, 'sqrt', True): [0.5506, 0.5363, 0.5412, 0.6869]\n",
            "('TfidfVectorizer', 300, 'sqrt', False): [0.5436, 0.5519, 0.5470, 0.6809]\n",
            "\n",
            "Наилучшая модель по аккуратности:\n",
            "\n",
            "('TfidfVectorizer', 200, 'log2', True)\n",
            "[0.5856513048729276, 0.5700429881555857, 0.5760549426827435, 0.7170351105331599]\n",
            "\n",
            "Наилучшая модель по F-мере:\n",
            "\n",
            "('TfidfVectorizer', 300, 'log2', False)\n",
            "[0.578288612555254, 0.5836625520493626, 0.5791202018957717, 0.7089726918075423]\n"
          ]
        }
      ]
    }
  ]
}